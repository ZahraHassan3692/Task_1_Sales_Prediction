# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nQWNr1CmktYPY7-wRmtbSr4ggV6WLBbb
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.metrics import mean_squared_error
from sklearn.impute import SimpleImputer

# Load the data
data = pd.read_csv('/content/train.csv')

# Display the first few rows
print(data.head())

# Display the shape of the data
print(data.shape)

# Display the summary statistics
print(data.describe())

# Display the data types of each column
print(data.dtypes)

# Display the number of missing values in each column
print(data.isnull().sum())

# Drop the 'Influencer' column if it exists
if 'Influencer' in data.columns:
    data.drop(['Influencer'], axis=1, inplace=True)

import pandas as pd  # Import the pandas library

# Load your data into a DataFrame
data = pd.read_csv('/content/train.csv')

# Fill missing values with the mean of each column

# Display the number of missing values in each column after imputation
print(data.isnull().sum())

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load your data into a DataFrame
data = pd.read_csv('/content/train.csv')

# Convert 'date' column to datetime object
data['date'] = pd.to_datetime(data['date'])  # Convert 'date' column to datetime

# Fill missing values with the mean of each column (for numerical columns only)
numeric_cols = data.select_dtypes(include=['number']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# Drop the 'Influencer' column if it exists
if 'Influencer' in data.columns:
    data.drop(['Influencer'], axis=1, inplace=True)

# Plot the correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True)
plt.show()

# Plot pairplot with kernel density estimate (kde) on the diagonal
sns.pairplot(data, diag_kind='kde')
plt.show()

# Plot histograms of all features
data.hist(figsize=(10, 10))
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load your data into a DataFrame
data = pd.read_csv('/content/train.csv')

# Convert 'date' column to datetime object
data['date'] = pd.to_datetime(data['date'])  # Convert 'date' column to datetime

# Fill missing values with the mean

x = data.drop('sales', axis=1)  # Replace 'sales' with your actual target column
y = data['sales']

import pandas as pd
from sklearn.linear_model import LinearRegression

# Assuming 'data' is your DataFrame with 'date' and 'sales' columns
# Convert 'date' column to datetime format if it isn't already
data['date'] = pd.to_datetime(data['date'])

# Convert 'date' to numerical features (e.g., days since the first date)
data['days_since_start'] = (data['date'] - data['date'].min()).dt.days

# Prepare features and target
x = data.drop(['sales', 'date'], axis=1)  # Drop original 'date' and target 'sales'
y = data['sales']

# Split data into training and testing sets
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

# Initialize and train the linear regression model
lr = LinearRegression()
lr.fit(x_train, y_train)  # Now fitting with numerical features

# Predict the target for the test set
pre = lr.predict(x_test)

# Display the predictions
print(pd.DataFrame(pre))

print(pre.shape)

# Evaluate the model
model_score = lr.score(x_test, y_test)
print('Model Score (Test):', model_score)

model_score_train = lr.score(x_train, y_train)
print('Model Score (Train):', model_score_train)

# Import the metrics module
from sklearn import metrics
import numpy as np # Import numpy

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, pre))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, pre)) # Use metrics.mean_squared_error here for consistency
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, pre))) # Now np.sqrt is available

# Combine actual and predicted values for comparison
y_grid = np.column_stack([y_test, pre])
print(pd.DataFrame(y_grid, columns=['Actual', 'Predicted']))

sns.regplot(x=y_test, y=pre)
plt.show()